{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../input/santander-value-prediction-challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/santander-value-prediction-challenge/train.csv')\n",
    "test_df = pd.read_csv('../input/santander-value-prediction-challenge/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and Remove Constant Features\n",
    "colsToRemove = []\n",
    "for i in train_df.columns:\n",
    "    if(i != \"ID\" and i != \"target\"):\n",
    "        if(train_df[i].std() ==0):\n",
    "            colsToRemove.append(i)\n",
    "            \n",
    "train_df.drop(colsToRemove,axis=1,inplace=True)\n",
    "\n",
    "test_df.drop(colsToRemove,axis=1,inplace=True)\n",
    "\n",
    "print('removed cols number: ',len(colsToRemove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicate Columns\n",
    "%%time\n",
    "\n",
    "# 방법1\n",
    "def duplicate_columns(frame):\n",
    "    groups = frame.columns.to_series().groupby(frame.dtypes).groups\n",
    "    dups = []\n",
    "    \n",
    "    for t,v in groups.items():\n",
    "        \n",
    "        cs = frame[v].columns\n",
    "        vs = frame[v]\n",
    "        lcs = len(cs)\n",
    "        \n",
    "        for i in range(lcs):\n",
    "            ia = vs.iloc[:,i].values\n",
    "            for j in range(i+1,lcs):\n",
    "                ja = vs.iloc[:,j].values\n",
    "                if np.array_equal(ia,ja):\n",
    "                    dups.append(cs[i])\n",
    "                    break\n",
    "    return dups\n",
    "\n",
    "colsToRemove = duplicate_columns(train_df)\n",
    "print(colsToRemove)\n",
    "        \n",
    "\n",
    "# 방법2 (추천 및 시도)\n",
    "train = train.loc[:, ~train.columns.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(colsToRemove,axis=1,inplace=True)\n",
    "test_df.drop(colsToRemove,axis=1,inplace=True)\n",
    "print(\"Removed dupliacte\",len(colsToRemove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Sparse Data\n",
    "\n",
    "def drop_sparse(train,test):\n",
    "    flist = [x for x in train.columns if not x in [\"ID\",\"target\"]]\n",
    "    for f in flist:\n",
    "        if len(np.unique(train[f]))<2:\n",
    "            train.drop(f,axis=1,inplace=True)\n",
    "            test.drop(f,axis=1,inplace=True)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df, test_df = drop_sparse(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop([\"ID\",\"target\"],axis=1)\n",
    "y_train = np.log1p(train_df['target'].values)\n",
    "\n",
    "x_test = test_df.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "\n",
    "def run_lgb(train_x,train_y,val_x,val_y,test_x):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.004,\n",
    "        \"bagging_fraction\" : 0.6,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbose\" : -1,\n",
    "        \"seed\":42\n",
    "    }\n",
    "    lgtrain = lgb.Dataset(train_x,label=train_y)\n",
    "    lgval = lgb.Dataset(val_x,label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params,lgtrain,5000,valid_sets=[lgtrain,lgval],\n",
    "                     early_stopping_rounds=100,verbose_eval=150,\n",
    "                     evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_x,num_iteration=model.best_iteration))\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test,model,evals_result = run_lgb(dev_x,dev_y,val_x,val_y,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "\n",
    "gain = model.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({\"feature\":model.feature_name(),\n",
    "                          \"split\":model.feature_importance(\"split\"),\n",
    "                          \"gain\":100*gain/gain.sum()}).sort_values('gain',ascending=False)\n",
    "print(featureimp[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Modeling\n",
    "\n",
    "def run_xgb(train_x,train_y,val_x,val_y,test_x):\n",
    "    params = {\"objective\": 'reg:linear',\n",
    "             'eval_metric' : 'rmse',\n",
    "             'eta' : 0.001,\n",
    "             'max_depth' : 10,\n",
    "             'subsample' : 0.6,\n",
    "             'colsample_bytree' : 0.6,\n",
    "             'alpha' : 0.001,\n",
    "             'randome_state' : 42,\n",
    "             'silent' : True}\n",
    "    \n",
    "    tr_data = xgb.DMatrix(train_x,train_y)\n",
    "    va_data = xgb.DMatrix(val_x,val_y)\n",
    "    \n",
    "    watchlist = [(tr_data,'train'),(va_data,'valid')]\n",
    "    \n",
    "    model_xgb = xgb.train(params,tr_data,2000,watchlist,maximize=False,\n",
    "                         early_stopping_rounds=100,verbose_eval=100)\n",
    "    dtest = xgb.DMatrix(test_x)\n",
    "    xgb_pred_y = np.expm1(model_xgb.predict(dtest,ntree_limit=model_xgb.best_ntree_limit))\n",
    "    \n",
    "    return xgb_pred_y,model_xgb\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_xgb,model_xgb = run_xgb(dev_x,dev_y,val_x,val_y,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost\n",
    "\n",
    "cb_model = CatBoostRegressor(iterations=500,\n",
    "                             learning_rate=0.05,\n",
    "                             depth=10,\n",
    "                             eval_metric='RMSE',\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 50,\n",
    "                             od_wait=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.fit(dev_X, dev_y,\n",
    "             eval_set=(val_X, val_y),\n",
    "             use_best_model=True,\n",
    "             verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_cat = np.expm1(cb_model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Predictions\n",
    "\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"target\"] = pred_test\n",
    "\n",
    "sub_xgb = pd.DataFrame()\n",
    "sub_xgb[\"target\"] = pred_test_xgb\n",
    "\n",
    "sub_cat = pd.DataFrame()\n",
    "sub_cat[\"target\"] = pred_test_cat\n",
    "\n",
    "sub[\"target\"] = (sub_lgb[\"target\"] * 0.5 + sub_xgb[\"target\"] * 0.3 + sub_cat[\"target\"] * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub.head())\n",
    "sub.to_csv('sub_lgb_xgb_cat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}